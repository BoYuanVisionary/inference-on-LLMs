# Inference-on-LLMs
This repository contains a list of key papers on **inference on LLMs**

## GitHub Repositories

- **Awesome LLM Strawberry (OpenAI o1)**  
 
  [A benchmark repository for research papers & blogs for OpenAI Strawberry(o1) and Reasoning.](https://github.com/hemingkx/Spec-Bench)

- **Speculative Decoding**
  
  [A regularly updated paper list for Speculative Decoding.](https://github.com/hemingkx/SpeculativeDecodingPapers/tree/main)


- **Reasoning**
  
  [A regularly updated paper list for LLM Reasoning.]( https://github.com/atfortes/Awesome-LLM-Reasoning)


## Papers

### Inference Scaling Laws

- **An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models**  
  Yangzhen Wu, Zhiqing Sun, Shanda Li, Sean Welleck, Yiming Yang, 2024.08. ![](https://img.shields.io/badge/Arxiv-orange)
  
- **Are More LM Calls All You Need?  Towards the Scaling Properties of Compound AI Systems**  
  Lingjiao Chen, Jared Quincy Davis, Boris Hanin, Peter Bailis, Ion Stoica, Matei Zaharia, James Zou, 2024.06. ![](https://img.shields.io/badge/Arxiv-orange)
  
- **Large Language Monkeys: Scaling Inference Compute  with Repeated Sampling**  
  Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V. Le, Christopher R ́e, and Azalia Mirhoseini, 2024.08. ![](https://img.shields.io/badge/Arxiv-orange)

- **Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters**  
  Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar, 2024.08. ![](https://img.shields.io/badge/DeepMind-blue)

- **The Larger the Better? Improved LLM Code-Generation via Budget Reallocation**  
  Michael Hassid, Tal Remez, Jonas Gehring, Roy Schwartz, Yossi Adi 2024.07. ![](https://img.shields.io/badge/COLM-orange) ![](https://img.shields.io/badge/OpenReview-orange)

### Reasoning

-  **Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning**    
  Amrith Setlur, Chirag Nagpal, Adam Fisch, Xinyang Geng, Jacob Eisenstein, Rishabh Agarwal, Alekh Agarwal, Jonathan Berant, Aviral Kumar
, 2024.10. ![](https://img.shields.io/badge/Arxiv-orange)![](https://img.shields.io/badge/DeepMind-blue)

-  **VerifierQ: Enhancing LLM Test Time Compute with Q-Learning-based Verifiers**    
  Jianing Qi, Hao Tang, Zhigang Zhu, 2024.10. ![](https://img.shields.io/badge/Arxiv-orange)

- **Training Verifiers to Solve Math Word Problems**  
  Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, 2021.11.  ![](https://img.shields.io/badge/OpenAI-blue)

- **Let's Verify Step by Step**  
  Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, Karl Cobbe, 2023.05.  ![](https://img.shields.io/badge/OpenAI-blue)

- **Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers**  
  Zhenting Qi, Mingyuan Ma, Jiahang Xu, Li Lyna Zhang, Fan Yang, Mao Yang, 2024.08.  ![](https://img.shields.io/badge/Microsoft-blue)

-  **Q<sup>*</sup>: Improving Multi-step Reasoning for LLMs with Deliberative Planning**    
  Chaojie Wang, Yanchen Deng, Zhiyi Lyu, Liang Zeng, Jujie He, Shuicheng Yan, Bo An, 2024.07. ![](https://img.shields.io/badge/Arxiv-orange)

- **Planning In Natural Language Improves LLM Search For Code Generation**  
  Evan Wang, Federico Cassano, Catherine Wu, Yunfeng Bai, Will Song, Vaskar Nath, Ziwen Han, Sean Hendryx, Summer Yue, Hugh Zhang, 2024.09.  ![](https://img.shields.io/badge/ScaleAI-blue)

- **Generative Verifiers: Reward Modeling as Next-Token Prediction**  
  Lunjun Zhang, Arian Hosseini, Hritik Bansal, Mehran Kazemi, Aviral Kumar, Rishabh Agarwal, 2024.08.  ![](https://img.shields.io/badge/OpenAI-blue)

#### MCTS

-  **LLaMA-Berry: Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning**    
 Di Zhang, Jianbo Wu, Jingdi Lei, Tong Che, Jiatong Li, Tong Xie, Xiaoshui Huang, Shufei Zhang, Marco Pavone, Yuqiang Li, Wanli Ouyang, Dongzhan Zhou, 2024.10. ![](https://img.shields.io/badge/Arxiv-orange)

-  **Towards Self-Improvement of LLMs via MCTS: Leveraging Stepwise Knowledge with Curriculum Preference Learning**    
  Xiyao Wang, Linfeng Song, Ye Tian, Dian Yu, Baolin Peng, Haitao Mi, Furong Huang, Dong Yu, 2024.10. ![](https://img.shields.io/badge/Arxiv-orange)

-  **Interpretable Contrastive Monte Carlo Tree Search Reasoning**    
  Zitian Gao, Boye Niu, Xuzheng He, Haotian Xu, Hongzhang Liu, Aiwei Liu, Xuming Hu, Lijie Wen, 2024.10. ![](https://img.shields.io/badge/Arxiv-orange)

-  **Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers**    
  Zhenting Qi, Mingyuan Ma, Jiahang Xu, Li Lyna Zhang, Fan Yang, Mao Yang, 2024.08. ![](https://img.shields.io/badge/Arxiv-orange)

-  **LLaMA-Berry: Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning**    
 Di Zhang, Jianbo Wu, Jingdi Lei, Tong Che, Jiatong Li, Tong Xie, Xiaoshui Huang, Shufei Zhang, Marco Pavone, Yuqiang Li, Wanli Ouyang, Dongzhan Zhou, 2024.10. ![](https://img.shields.io/badge/Arxiv-orange)

-  **Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B**    
  Di Zhang, Xiaoshui Huang, Dongzhan Zhou, Yuqiang Li, Wanli Ouyang, 2024.06. ![](https://img.shields.io/badge/Arxiv-orange)

-  **Step-level Value Preference Optimization for Mathematical Reasoning**    
  Guoxin Chen, Minpeng Liao, Chengxi Li, Kai Fan., 2024.06. ![](https://img.shields.io/badge/Arxiv-orange)

-  **Improve Mathematical Reasoning in Language Models by Automated Process Supervision**    
  Liangchen Luo, Yinxiao Liu, Rosanne Liu, Samrat Phatale, Harsh Lara, Yunxuan Li, Lei Shu, Yun Zhu, Lei Meng, Jiao Sun, Abhinav Rastogi, 2024.06. ![](https://img.shields.io/badge/DeepMind-blue)

-  **AlphaMath Almost Zero: Process Supervision Without Process**    
  Guoxin Chen, Minpeng Liao, Chengxi Li, Kai Fan., 2024.05. ![](https://img.shields.io/badge/Arxiv-orange)

-  **ReST-MCTS: LLM Self-Training via Process Reward Guided Tree Search**    
  Dan Zhang, Sining Zhoubian, Yisong Yue, Yuxiao Dong, and Jie Tang.., 2024.06. ![](https://img.shields.io/badge/Arxiv-orange)

-  **Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning**    
  Yuxi Xie, Anirudh Goyal, Wenyue Zheng, Min-Yen Kan, Timothy P. Lillicrap, Kenji Kawaguchi, Michael Shieh, 2024.06. ![](https://img.shields.io/badge/Arxiv-orange)

-  **Training Chain-of-Thought via Latent-Variable Inference**    
  Du Phan, Matthew D. Hoffman, David Dohan, Sholto Douglas, Tuan Anh Le, Aaron Parisi, Pavel Sountsov, Charles Sutton, Sharad Vikram, Rif A. Saurous, 2023.11. ![](https://img.shields.io/badge/Google-blue)  ![](https://img.shields.io/badge/NIPS-orange)

-  **Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training**    
  Xidong Feng, Ziyu Wan, Muning Wen, Stephen Marcus McAleer, Ying Wen, Weinan Zhang, Jun Wang
, 2023.11. ![](https://img.shields.io/badge/NIPS_FMDM_Workshop-orange)

-  **Reasoning with Language Model is Planning with World Model**    
  Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu
, 2023.10. ![](https://img.shields.io/badge/EMNLP-orange)

-  **Don’t throw away your value model! Generating more preferable text with Value-Guided Monte-Carlo Tree Search decoding**    
  Liu, Jiacheng, Andrew Cohen, Ramakanth Pasunuru, Yejin Choi, Hannaneh Hajishirzi, and Asli Celikyilmaz.
, 2023.09. ![](https://img.shields.io/badge/COLM-orange)

-  **Large Language Models as Commonsense Knowledge for Large-Scale Task Planning**    
  Zirui Zhao, Wee Sun Lee, David Hsu, 2023.05. ![](https://img.shields.io/badge/NIPS-orange)



### RLHF

-  **Transfer Q Star: Principled Decoding for LLM Alignment**    
Souradip Chakraborty, Soumya Suvra Ghosal, Ming Yin, Dinesh Manocha, Mengdi Wang, Amrit Singh Bedi, Furong Huang, 2024.05. ![](https://img.shields.io/badge/Arxiv-orange)

### Theoretical Understanding

- **Chain of Thought Empowers Transformers to Solve Inherently Serial Problems**  
  Zhiyuan Li, Hong Liu, Denny Zhou, Tengyu Ma 2024.01. ![](https://img.shields.io/badge/ICLR-orange) ![](https://img.shields.io/badge/OpenReview-orange)


- **From r to Q∗: Your Language Model is Secretly a Q-Function**  
  Rafael Rafailov, Joey Hejna, Ryan Park, Chelsea Finn 2024.04. ![](https://img.shields.io/badge/COLM-orange)



### Survey

- **Towards a Unified View of Preference Learning for Large Language Models: A Survey**  
  Bofei Gao, Feifan Song, Yibo Miao, Zefan Cai, Zhe Yang, Liang Chen, Helan Hu,... 2024.09. ![](https://img.shields.io/badge/Arxiv-orange)
  
### Other Relevant Works

- **Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling**  
  Hritik Bansal, Arian Hosseini, Rishabh Agarwal, Vinh Q. Tran, Mehran Kazemi 2024.08. ![](https://img.shields.io/badge/DeepMind-blue)


- **To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning**    
Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, Greg Durrett, 2024.09. ![](https://img.shields.io/badge/Arxiv-orange)


### VLM & Planning

- **Improving Autonomous AI Agents with Reflective Tree Search and Self-Learning**    
Xiao Yu, Baolin Peng, Vineeth Vajipey, Hao Cheng, Michel Galley, Jianfeng Gao, Zhou Yu, 2024.10. ![](https://img.shields.io/badge/Arxiv-orange)



